#!/usr/bin/env python
"""RAG ç³»ç»Ÿå®Œæ•´ä½¿ç”¨ç¤ºä¾‹ã€‚

æ¼”ç¤ºåŠŸèƒ½ï¼š
1. åˆå§‹åŒ– RAG Pipeline
2. æ–‡æœ¬è½½å…¥ä¸æ™ºèƒ½åˆ†å—
3. æ–‡ä»¶è½½å…¥ï¼ˆMarkItDown è½¬æ¢ï¼‰
4. åŸºç¡€å‘é‡æ£€ç´¢
5. é«˜çº§æ£€ç´¢ç­–ç•¥ï¼ˆMQE / HyDEï¼‰
6. LLM å¢å¼ºé—®ç­”
7. çŸ¥è¯†åº“ç®¡ç†ä¸ç»Ÿè®¡
8. æ¸…ç©ºçŸ¥è¯†åº“

è¿è¡Œå‰è¯·ç¡®ä¿è®¾ç½®å¥½ç¯å¢ƒå˜é‡ï¼š
- QDRANT_URL / QDRANT_API_KEY
- EMBED_BASE_URL / EMBED_API_KEY / EMBED_MODEL_NAME
- PROVIDER, ZHIPU_BASE_URL, ZHIPU_API_KEY ç­‰ï¼ˆLLM é—®ç­”åŠŸèƒ½éœ€è¦ï¼‰
"""

from __future__ import annotations

import os
import sys
import tempfile

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ path ä¸­
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))

from dotenv import load_dotenv

load_dotenv()


def separator(title: str) -> None:
    print(f"\n{'='*60}")
    print(f"  {title}")
    print(f"{'='*60}\n")


def demo_1_init_pipeline():
    """1. åˆå§‹åŒ– RAG Pipeline"""
    separator("1. åˆå§‹åŒ– RAG Pipeline")

    from veragents.memory.rag.pipeline import RAGPipeline

    pipeline = RAGPipeline(
        knowledge_base_path="./knowledge_base_demo",
        collection_name="rag_demo",
        rag_namespace="demo",
        chunk_tokens=256,
        overlap_tokens=32,
    )

    print(f"âœ… Pipeline åˆå§‹åŒ–æˆåŠŸ")
    print(f"   çŸ¥è¯†åº“è·¯å¾„: {pipeline.knowledge_base_path}")
    print(f"   å‘é‡é›†åˆ: {pipeline.collection_name}")
    print(f"   å‘½åç©ºé—´: {pipeline.rag_namespace}")
    print(f"   åµŒå…¥ç»´åº¦: {pipeline.dimension}")
    print(f"   åˆ†å—å¤§å°: {pipeline.chunk_tokens} tokens")
    print(f"   é‡å : {pipeline.overlap_tokens} tokens")

    return pipeline


def demo_2_smart_chunking():
    """2. æ™ºèƒ½ Markdown åˆ†å—æ¼”ç¤º"""
    separator("2. æ™ºèƒ½ Markdown åˆ†å—")

    from veragents.memory.rag.pipeline import smart_chunk_markdown, _approx_token_len

    sample_md = """# æ·±åº¦å­¦ä¹ åŸºç¡€

## 1. ç¥ç»ç½‘ç»œæ¦‚è¿°

ç¥ç»ç½‘ç»œæ˜¯ä¸€ç§æ¨¡æ‹Ÿäººè„‘ç¥ç»å…ƒè¿æ¥çš„è®¡ç®—æ¨¡å‹ã€‚å®ƒç”±è¾“å…¥å±‚ã€éšè—å±‚å’Œè¾“å‡ºå±‚ç»„æˆã€‚
æ¯ä¸ªç¥ç»å…ƒæ¥æ”¶è¾“å…¥ä¿¡å·ï¼Œç»è¿‡åŠ æƒæ±‚å’Œå’Œæ¿€æ´»å‡½æ•°å¤„ç†åï¼Œäº§ç”Ÿè¾“å‡ºã€‚

æ·±åº¦å­¦ä¹ æ˜¯ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œçš„æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚éšç€å±‚æ•°çš„å¢åŠ ï¼Œç½‘ç»œèƒ½å¤Ÿå­¦ä¹ åˆ°è¶Šæ¥è¶ŠæŠ½è±¡çš„ç‰¹å¾è¡¨ç¤ºã€‚

## 2. å¸¸è§æ¶æ„

### 2.1 å·ç§¯ç¥ç»ç½‘ç»œ (CNN)

CNN ä¸“é—¨ç”¨äºå¤„ç†å…·æœ‰ç½‘æ ¼ç»“æ„çš„æ•°æ®ï¼Œå¦‚å›¾åƒã€‚å…¶æ ¸å¿ƒæ“ä½œåŒ…æ‹¬ï¼š
- **å·ç§¯å±‚**ï¼šä½¿ç”¨å·ç§¯æ ¸æå–å±€éƒ¨ç‰¹å¾
- **æ± åŒ–å±‚**ï¼šé™ä½ç‰¹å¾å›¾çš„ç©ºé—´ç»´åº¦
- **å…¨è¿æ¥å±‚**ï¼šè¿›è¡Œæœ€ç»ˆçš„åˆ†ç±»æˆ–å›å½’

### 2.2 å¾ªç¯ç¥ç»ç½‘ç»œ (RNN)

RNN æ“…é•¿å¤„ç†åºåˆ—æ•°æ®ï¼Œå¦‚æ–‡æœ¬å’Œæ—¶é—´åºåˆ—ã€‚å®ƒé€šè¿‡éšè—çŠ¶æ€åœ¨æ—¶é—´æ­¥ä¹‹é—´ä¼ é€’ä¿¡æ¯ã€‚
LSTM å’Œ GRU æ˜¯ RNN çš„æ”¹è¿›ç‰ˆæœ¬ï¼Œè§£å†³äº†é•¿è·ç¦»ä¾èµ–é—®é¢˜ã€‚

### 2.3 Transformer

Transformer åŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼Œå®Œå…¨æ‘’å¼ƒäº†å¾ªç¯ç»“æ„ã€‚å®ƒæ˜¯ BERTã€GPT ç­‰å¤§è¯­è¨€æ¨¡å‹çš„åŸºç¡€ã€‚
è‡ªæ³¨æ„åŠ›æœºåˆ¶å…è®¸æ¨¡å‹åœ¨å¤„ç†æ¯ä¸ªä½ç½®æ—¶ï¼ŒåŒæ—¶å…³æ³¨è¾“å…¥åºåˆ—çš„æ‰€æœ‰ä½ç½®ã€‚

## 3. è®­ç»ƒæŠ€æœ¯

### 3.1 ä¼˜åŒ–å™¨

- Adamï¼šè‡ªé€‚åº”å­¦ä¹ ç‡ä¼˜åŒ–å™¨ï¼Œç»“åˆäº† Momentum å’Œ RMSProp çš„ä¼˜ç‚¹
- SGDï¼šéšæœºæ¢¯åº¦ä¸‹é™ï¼Œæ˜¯æœ€åŸºç¡€çš„ä¼˜åŒ–ç®—æ³•
- AdamWï¼šåœ¨ Adam åŸºç¡€ä¸ŠåŠ å…¥æƒé‡è¡°å‡

### 3.2 æ­£åˆ™åŒ–

- Dropoutï¼šéšæœºä¸¢å¼ƒç¥ç»å…ƒï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
- Batch Normalizationï¼šæ ‡å‡†åŒ–å±‚è¾“å…¥ï¼ŒåŠ é€Ÿè®­ç»ƒ
- Label Smoothingï¼šè½¯åŒ–æ ‡ç­¾ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›
"""

    chunks = smart_chunk_markdown(sample_md, chunk_tokens=100, overlap_tokens=16)

    print(f"åŸå§‹æ–‡æœ¬é•¿åº¦: {len(sample_md)} chars, ~{_approx_token_len(sample_md)} tokens")
    print(f"åˆ†å—æ•°é‡: {len(chunks)}")
    print()

    for i, chunk in enumerate(chunks):
        print(f"--- åˆ†å— {i} ({chunk['token_estimate']} tokens) ---")
        heading = chunk.get("heading_path", "")
        if heading:
            print(f"    æ ‡é¢˜è·¯å¾„: {heading}")
        content_preview = chunk["content"][:80].replace("\n", " ")
        print(f"    å†…å®¹: {content_preview}...")
        print()

    return sample_md


def demo_3_ingest_text(pipeline):
    """3. æ–‡æœ¬è½½å…¥"""
    separator("3. è½½å…¥æ–‡æœ¬åˆ°çŸ¥è¯†åº“")

    knowledge_texts = [
        (
            "Python ç¼–ç¨‹è¯­è¨€",
            """# Python ç¼–ç¨‹è¯­è¨€

Python æ˜¯ä¸€ç§é«˜çº§ã€é€šç”¨çš„ç¼–ç¨‹è¯­è¨€ã€‚å®ƒçš„è®¾è®¡å“²å­¦å¼ºè°ƒä»£ç çš„å¯è¯»æ€§å’Œç®€æ´æ€§ã€‚

## æ ¸å¿ƒç‰¹æ€§

- **åŠ¨æ€ç±»å‹**ï¼šå˜é‡ä¸éœ€è¦å£°æ˜ç±»å‹
- **è§£é‡Šæ‰§è¡Œ**ï¼šä»£ç é€è¡Œè§£é‡Šæ‰§è¡Œï¼Œæ— éœ€ç¼–è¯‘
- **ä¸°å¯Œçš„æ ‡å‡†åº“**ï¼šå†…ç½®å¤§é‡å®ç”¨æ¨¡å—
- **å¤šèŒƒå¼æ”¯æŒ**ï¼šæ”¯æŒé¢å‘å¯¹è±¡ã€å‡½æ•°å¼ç­‰å¤šç§ç¼–ç¨‹èŒƒå¼

## å¸¸è§åº”ç”¨

Python å¹¿æ³›åº”ç”¨äº Web å¼€å‘ã€æ•°æ®ç§‘å­¦ã€äººå·¥æ™ºèƒ½ã€è‡ªåŠ¨åŒ–è¿ç»´ç­‰é¢†åŸŸã€‚
Django å’Œ Flask æ˜¯æµè¡Œçš„ Web æ¡†æ¶ã€‚
NumPyã€Pandas å’Œ Scikit-learn æ˜¯æ•°æ®ç§‘å­¦çš„æ ¸å¿ƒåº“ã€‚
TensorFlow å’Œ PyTorch æ˜¯ä¸»æµçš„æ·±åº¦å­¦ä¹ æ¡†æ¶ã€‚
""",
        ),
        (
            "å‘é‡æ•°æ®åº“ä»‹ç»",
            """# å‘é‡æ•°æ®åº“

å‘é‡æ•°æ®åº“æ˜¯ä¸“é—¨ç”¨äºå­˜å‚¨å’Œæ£€ç´¢é«˜ç»´å‘é‡çš„æ•°æ®åº“ç³»ç»Ÿã€‚

## å·¥ä½œåŸç†

å‘é‡æ•°æ®åº“é€šè¿‡è¿‘ä¼¼æœ€è¿‘é‚»ï¼ˆANNï¼‰ç®—æ³•æ¥å®ç°é«˜æ•ˆçš„ç›¸ä¼¼æ€§æœç´¢ã€‚
å¸¸ç”¨çš„ ANN ç®—æ³•åŒ…æ‹¬ HNSWã€IVFã€PQ ç­‰ã€‚

## ä¸»æµäº§å“

- **Qdrant**ï¼šåŸºäº Rust å¼€å‘ï¼Œæ”¯æŒè¿‡æ»¤æ£€ç´¢
- **Milvus**ï¼šCNCF é¡¹ç›®ï¼Œæ”¯æŒå¤šç§ç´¢å¼•ç±»å‹
- **Pinecone**ï¼šå…¨æ‰˜ç®¡äº‘æœåŠ¡
- **Weaviate**ï¼šæ”¯æŒæ¨¡å—åŒ–å‘é‡åŒ–

## åº”ç”¨åœºæ™¯

1. RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰
2. æ¨èç³»ç»Ÿ
3. å›¾åƒ/éŸ³é¢‘æœç´¢
4. å¼‚å¸¸æ£€æµ‹
""",
        ),
        (
            "å¤§è¯­è¨€æ¨¡å‹æ¦‚è¿°",
            """# å¤§è¯­è¨€æ¨¡å‹ (LLM)

å¤§è¯­è¨€æ¨¡å‹æ˜¯åŸºäº Transformer æ¶æ„çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚

## ä»£è¡¨æ¨¡å‹

- **GPT ç³»åˆ—**ï¼šOpenAI çš„è‡ªå›å½’è¯­è¨€æ¨¡å‹
- **BERT**ï¼šGoogle çš„åŒå‘ç¼–ç æ¨¡å‹
- **LLaMA**ï¼šMeta å¼€æºçš„å¤§æ¨¡å‹ç³»åˆ—
- **é€šä¹‰åƒé—®**ï¼šé˜¿é‡Œçš„å¤§æ¨¡å‹
- **GLM**ï¼šæ™ºè°±çš„å¯¹è¯å¤§æ¨¡å‹

## RAG æŠ€æœ¯

RAGï¼ˆRetrieval-Augmented Generationï¼‰æ˜¯å°†æ£€ç´¢å’Œç”Ÿæˆç»“åˆçš„æŠ€æœ¯ã€‚
æ ¸å¿ƒæ€æƒ³æ˜¯åœ¨ç”Ÿæˆå›ç­”å‰ï¼Œå…ˆä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£ã€‚
è¿™æ ·å¯ä»¥å‡å°‘å¤§æ¨¡å‹çš„å¹»è§‰é—®é¢˜ï¼Œæé«˜å›ç­”çš„å‡†ç¡®æ€§å’Œæ—¶æ•ˆæ€§ã€‚

## å¾®è°ƒæŠ€æœ¯

- LoRAï¼šä½ç§©é€‚åº”ï¼Œå‚æ•°é«˜æ•ˆå¾®è°ƒ
- QLoRAï¼šé‡åŒ–ä½ç§©é€‚åº”
- Full Fine-tuningï¼šå…¨é‡å¾®è°ƒ
- Instruction Tuningï¼šæŒ‡ä»¤å¾®è°ƒ
""",
        ),
    ]

    total_chunks = 0
    for source_name, text in knowledge_texts:
        count = pipeline.ingest_text(text, source=source_name)
        total_chunks += count
        print(f"âœ… å·²è½½å…¥: {source_name} â†’ {count} ä¸ªåˆ†å—")

    print(f"\næ€»è®¡è½½å…¥: {total_chunks} ä¸ªåˆ†å—")
    return total_chunks


def demo_4_ingest_file(pipeline):
    """4. æ–‡ä»¶è½½å…¥ï¼ˆMarkItDown è½¬æ¢ï¼‰"""
    separator("4. æ–‡ä»¶è½½å…¥")

    # åˆ›å»ºä¸´æ—¶æµ‹è¯•æ–‡ä»¶
    with tempfile.NamedTemporaryFile(mode="w", suffix=".md", delete=False, encoding="utf-8") as f:
        f.write("""# VerAgents æ¡†æ¶ä»‹ç»

VerAgents æ˜¯ä¸€ä¸ªæ¨¡å—åŒ–çš„ AI Agent æ¡†æ¶ã€‚

## æ ¸å¿ƒæ¨¡å—

### è®°å¿†ç³»ç»Ÿ

VerAgents çš„è®°å¿†ç³»ç»ŸåŒ…å«å››ç§è®°å¿†ç±»å‹ï¼š
- **å·¥ä½œè®°å¿†**ï¼šçŸ­æœŸä¸Šä¸‹æ–‡ï¼Œå®¹é‡æœ‰é™
- **æƒ…æ™¯è®°å¿†**ï¼šå…·ä½“äº¤äº’äº‹ä»¶è®°å½•
- **è¯­ä¹‰è®°å¿†**ï¼šæ¦‚å¿µå’ŒçŸ¥è¯†å­˜å‚¨
- **æ„ŸçŸ¥è®°å¿†**ï¼šå¤šæ¨¡æ€æ•°æ®å¤„ç†

### RAG ç³»ç»Ÿ

RAG ç³»ç»Ÿæ˜¯ä¸€ç§å·¥å…·ï¼Œæä¾›æ–‡æ¡£è½½å…¥ã€æ™ºèƒ½æ£€ç´¢å’Œ LLM å¢å¼ºé—®ç­”åŠŸèƒ½ã€‚
æ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼ŒåŒ…æ‹¬ PDFã€Wordã€Excel ç­‰ã€‚

### å·¥å…·ç³»ç»Ÿ

VerAgents æä¾›å¯æ‰©å±•çš„å·¥å…·æ³¨å†Œæœºåˆ¶ï¼Œæ”¯æŒè‡ªå®šä¹‰å·¥å…·ã€‚
""")
        tmp_path = f.name

    try:
        count = pipeline.ingest_file(tmp_path)
        print(f"âœ… æ–‡ä»¶è½½å…¥æˆåŠŸ: {os.path.basename(tmp_path)} â†’ {count} ä¸ªåˆ†å—")
    finally:
        os.unlink(tmp_path)

    return count


def demo_5_basic_search(pipeline):
    """5. åŸºç¡€å‘é‡æ£€ç´¢"""
    separator("5. åŸºç¡€å‘é‡æ£€ç´¢")

    queries = [
        "Python å¯ä»¥ç”¨æ¥åšä»€ä¹ˆ",
        "ä»€ä¹ˆæ˜¯å‘é‡æ•°æ®åº“",
        "RAG æŠ€æœ¯çš„åŸç†",
        "æ·±åº¦å­¦ä¹ æ¡†æ¶æœ‰å“ªäº›",
    ]

    for query in queries:
        print(f"ğŸ” æŸ¥è¯¢: {query}")
        results = pipeline.search(query=query, top_k=3)
        for i, r in enumerate(results, 1):
            score = r["score"]
            heading = r.get("heading_path", "")
            heading_str = f" [{heading}]" if heading else ""
            content_preview = r["content"][:60].replace("\n", " ")
            print(f"   {i}. [score={score:.3f}]{heading_str} {content_preview}...")
        print()


def demo_6_advanced_search(pipeline):
    """6. é«˜çº§æ£€ç´¢ç­–ç•¥"""
    separator("6. é«˜çº§æ£€ç´¢ç­–ç•¥ï¼ˆMQE / HyDEï¼‰")

    query = "å¦‚ä½•ä½¿ç”¨ RAG æŠ€æœ¯æé«˜é—®ç­”å‡†ç¡®æ€§"

    # åŸºç¡€æ£€ç´¢
    print(f"ğŸ” åŸå§‹æŸ¥è¯¢: {query}\n")

    print("--- åŸºç¡€æ£€ç´¢ ---")
    results_basic = pipeline.search(query=query, top_k=3)
    for i, r in enumerate(results_basic, 1):
        content_preview = r["content"][:60].replace("\n", " ")
        print(f"   {i}. [score={r['score']:.3f}] {content_preview}...")

    # MQE æ£€ç´¢
    print("\n--- MQE å¤šæŸ¥è¯¢æ‰©å±•æ£€ç´¢ ---")
    try:
        results_mqe = pipeline.search(query=query, top_k=3, enable_mqe=True, mqe_expansions=2)
        for i, r in enumerate(results_mqe, 1):
            content_preview = r["content"][:60].replace("\n", " ")
            print(f"   {i}. [score={r['score']:.3f}] {content_preview}...")
    except Exception as e:
        print(f"   âš ï¸ MQE éœ€è¦ LLM æ”¯æŒ: {e}")

    # HyDE æ£€ç´¢
    print("\n--- HyDE å‡è®¾æ–‡æ¡£æ£€ç´¢ ---")
    try:
        results_hyde = pipeline.search(query=query, top_k=3, enable_hyde=True)
        for i, r in enumerate(results_hyde, 1):
            content_preview = r["content"][:60].replace("\n", " ")
            print(f"   {i}. [score={r['score']:.3f}] {content_preview}...")
    except Exception as e:
        print(f"   âš ï¸ HyDE éœ€è¦ LLM æ”¯æŒ: {e}")


def demo_7_rag_query(pipeline):
    """7. LLM å¢å¼ºé—®ç­”"""
    separator("7. LLM å¢å¼ºé—®ç­”")

    questions = [
        "Python æœ‰å“ªäº›ä¸»è¦çš„åº”ç”¨é¢†åŸŸï¼Ÿ",
        "RAG æŠ€æœ¯æ˜¯ä»€ä¹ˆï¼Ÿå®ƒèƒ½è§£å†³ä»€ä¹ˆé—®é¢˜ï¼Ÿ",
    ]

    for question in questions:
        print(f"â“ é—®é¢˜: {question}\n")
        try:
            result = pipeline.query(question=question, top_k=3)
            print(f"ğŸ’¡ å›ç­”:\n{result['answer']}\n")
            print(f"ğŸ“š å‚è€ƒæ¥æº: {result['sources_count'] if 'sources_count' in result else len(result['sources'])} æ¡")
            for i, src in enumerate(result["sources"][:3], 1):
                source_name = src.get("source", "unknown")
                print(f"   {i}. [{src['score']:.3f}] {source_name}")
        except Exception as e:
            print(f"   âš ï¸ LLM é—®ç­”éœ€è¦é…ç½® Provider: {e}")
        print()


def demo_8_stats(pipeline):
    """8. çŸ¥è¯†åº“ç»Ÿè®¡"""
    separator("8. çŸ¥è¯†åº“ç»Ÿè®¡")

    stats = pipeline.get_stats()

    print(f"å‘½åç©ºé—´: {stats['namespace']}")
    print(f"å‘é‡é›†åˆ: {stats['collection']}")
    print(f"å·²ç´¢å¼•æ–‡ä»¶æ•°: {stats['indexed_files']}")
    print(f"æ€»åˆ†å—æ•°: {stats['total_chunks']}")
    print(f"åµŒå…¥ç»´åº¦: {stats['dimension']}")
    print(f"åˆ†å—é…ç½®: {stats['chunk_config']}")

    vs = stats.get("vector_store", {})
    if vs:
        print(f"å‘é‡å­˜å‚¨: {vs}")

    ds = stats.get("document_store", {})
    if ds:
        print(f"æ–‡æ¡£å­˜å‚¨: {ds}")


def demo_9_cleanup(pipeline):
    """9. æ¸…ç©ºçŸ¥è¯†åº“"""
    separator("9. æ¸…ç©ºçŸ¥è¯†åº“")

    pipeline.clear()
    print("âœ… çŸ¥è¯†åº“å·²æ¸…ç©º")

    import shutil
    kb_path = "./knowledge_base_demo"
    if os.path.exists(kb_path):
        shutil.rmtree(kb_path)
        print(f"âœ… å·²åˆ é™¤ä¸´æ—¶ç›®å½•: {kb_path}")


def main():
    """RAG ç³»ç»Ÿå®Œæ•´æ¼”ç¤ºã€‚"""
    print()
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘         VerAgents RAG ç³»ç»Ÿ å®Œæ•´ä½¿ç”¨ç¤ºä¾‹                 â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

    # 1. åˆå§‹åŒ–
    pipeline = demo_1_init_pipeline()

    # 2. åˆ†å—æ¼”ç¤ºï¼ˆç‹¬ç«‹ï¼Œä¸å½±å“ pipelineï¼‰
    demo_2_smart_chunking()

    # 3. è½½å…¥æ–‡æœ¬
    demo_3_ingest_text(pipeline)

    # 4. è½½å…¥æ–‡ä»¶
    demo_4_ingest_file(pipeline)

    # 5. åŸºç¡€æ£€ç´¢
    demo_5_basic_search(pipeline)

    # 6. é«˜çº§æ£€ç´¢ï¼ˆMQE/HyDE éœ€è¦ LLMï¼‰
    demo_6_advanced_search(pipeline)

    # 7. LLM é—®ç­”
    demo_7_rag_query(pipeline)

    # 8. ç»Ÿè®¡
    demo_8_stats(pipeline)

    # 9. æ¸…ç†
    demo_9_cleanup(pipeline)

    print()
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘          âœ… RAG ç³»ç»Ÿæ¼”ç¤ºå®Œæˆ                            â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")


if __name__ == "__main__":
    main()
